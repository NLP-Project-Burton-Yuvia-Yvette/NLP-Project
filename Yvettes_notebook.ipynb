{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b6738dc",
   "metadata": {},
   "source": [
    "# Yvettes Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdb91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from env import github_token, github_username\n",
    "import re\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1642cb19",
   "metadata": {},
   "source": [
    "### Acquire webscrape urls from repos and save to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f51d4e",
   "metadata": {},
   "source": [
    "Keytakaway from urls collection:\n",
    "After some exploration of urls in github search of most starred repos we noticed that the page number in the url was the only change from one page to another. Creating a loop to change page when web scraping will allow us to \n",
    "iterate through pages and get more urls into our csv file.\n",
    "\n",
    "We also notice that the link to the repo was under <a> class = \"v-align-middle\". We will add a forloop to scrape each link and remove the first \"/\" and save into csv file.\n",
    "    \n",
    "In total we were able to collect 1000 observation of urls 853 of which seem to be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb461327",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #'search?q=stars%3A%3E0&s=stars&type=Repositories'\n",
    "    #'search?p=2&q=stars%3A%3E0&s=stars&type=Repositories'\n",
    "    #'search?p=3&q=stars%3A%3E0&s=stars&type=Repositories'\n",
    "    \n",
    "#https://github.com/search?q=stars%3A%3E0&s=stars&type=Repositories\n",
    "#https://github.com/search?p=100&q=stars%3A%3E0&s=stars&type=Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7631ba32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#urls=[]\n",
    "#for i in range(0,100):\n",
    "#    url = f\"https://github.com/search?p={i}&q=stars%3A%3E0&s=stars&type=Repositories\"\n",
    "#    reqs = requests.get(url)\n",
    "#    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "#    time.sleep(2)\n",
    "#    for link in soup.find_all('a',class_=\"v-align-middle\"):\n",
    "#        link = re.sub(r'/', '', link.get('href'), count = 1)\n",
    "#        urls.append(link)\n",
    "#        time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c2cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls =pd.DataFrame(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e226b92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#urls.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18bb72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls.to_csv('urls_final1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27d2228",
   "metadata": {},
   "source": [
    "### acquire content of urls readme "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf89bbc",
   "metadata": {},
   "source": [
    "We will call on our saved urls_final.csv file to scrape the content of the repos of ReadMe text, main language of code. We will then save the information along with the repos name into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e48e264b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freeCodeCamp/freeCodeCamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>getify/You-Dont-Know-JS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft/vscode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>electron/electron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>axios/axios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>attic-labs/noms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>libretro/RetroArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>score-spec/spec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>ThreeMammals/Ocelot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>developit/microbundle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "0    freeCodeCamp/freeCodeCamp\n",
       "1      getify/You-Dont-Know-JS\n",
       "2             microsoft/vscode\n",
       "3            electron/electron\n",
       "4                  axios/axios\n",
       "..                         ...\n",
       "995            attic-labs/noms\n",
       "996         libretro/RetroArch\n",
       "997            score-spec/spec\n",
       "998        ThreeMammals/Ocelot\n",
       "999      developit/microbundle\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_repo = pd.read_csv('urls_final.csv', index_col=0)\n",
    "urls_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "781b8ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freeCodeCamp/freeCodeCamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>getify/You-Dont-Know-JS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft/vscode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>electron/electron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>axios/axios</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "0  freeCodeCamp/freeCodeCamp\n",
       "1    getify/You-Dont-Know-JS\n",
       "2           microsoft/vscode\n",
       "3          electron/electron\n",
       "4                axios/axios"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_repo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2bee17da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    853\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_repo.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5a18a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_repo.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "913b4f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>bootstrap-vue/bootstrap-vue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>sharkdp/hyperfine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>Rigellute/spotify-tui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>williamfiset/Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>jina-ai/jina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>dropzone/dropzone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>ethereumbook/ethereumbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>chaozh/awesome-blockchain-cn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>eip-work/kuboard-press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>semantic-release/semantic-release</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "526        bootstrap-vue/bootstrap-vue\n",
       "527                  sharkdp/hyperfine\n",
       "528              Rigellute/spotify-tui\n",
       "529            williamfiset/Algorithms\n",
       "530                       jina-ai/jina\n",
       "531                  dropzone/dropzone\n",
       "532          ethereumbook/ethereumbook\n",
       "533       chaozh/awesome-blockchain-cn\n",
       "534             eip-work/kuboard-press\n",
       "535  semantic-release/semantic-release"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_repo[460:470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "85ab5610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    eip-work/kuboard-press\n",
       "Name: 534, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_repo.iloc[468]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5ca4444e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[534] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [144]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# scrapping functions where not functionin properly because url index 468 no longer existed, so it was dropped.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#0    eip-work/kuboard-press\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Name: 534, dtype: object\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43murls_repo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m534\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4816\u001b[0m ):\n\u001b[1;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[534] not found in axis'"
     ]
    }
   ],
   "source": [
    "# scrapping functions where not functionin properly because url index 468 no longer existed, so it was dropped.\n",
    "#0    eip-work/kuboard-press\n",
    "#Name: 534, dtype: object\n",
    "urls_repo.drop([534], axis = 0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "98a15fba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>bootstrap-vue/bootstrap-vue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>sharkdp/hyperfine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>Rigellute/spotify-tui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>williamfiset/Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>jina-ai/jina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>dropzone/dropzone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>ethereumbook/ethereumbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>chaozh/awesome-blockchain-cn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>semantic-release/semantic-release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>framework7io/framework7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "526        bootstrap-vue/bootstrap-vue\n",
       "527                  sharkdp/hyperfine\n",
       "528              Rigellute/spotify-tui\n",
       "529            williamfiset/Algorithms\n",
       "530                       jina-ai/jina\n",
       "531                  dropzone/dropzone\n",
       "532          ethereumbook/ethereumbook\n",
       "533       chaozh/awesome-blockchain-cn\n",
       "535  semantic-release/semantic-release\n",
       "537            framework7io/framework7"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_repo[460:470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "57669ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_repo.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b4c69258",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_repo.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5ca576f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freeCodeCamp/freeCodeCamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>getify/You-Dont-Know-JS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft/vscode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>electron/electron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>axios/axios</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "0  freeCodeCamp/freeCodeCamp\n",
       "1    getify/You-Dont-Know-JS\n",
       "2           microsoft/vscode\n",
       "3          electron/electron\n",
       "4                axios/axios"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_repo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8a17add9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ethereumbook/ethereumbook\n",
       "Name: 466, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_repo.iloc[466]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5ddca0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A module for obtaining repo readme and language data from the github API.\n",
    "Before using this module, read through it, and follow the instructions marked\n",
    "TODO.\n",
    "After doing so, run it like this:\n",
    "    python acquire.py\n",
    "To create the `data.json` file that contains the data.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# TODO: Make a github personal access token.\n",
    "#     1. Go here and generate a personal access token: https://github.com/settings/tokens\n",
    "#        You do _not_ need select any scopes, i.e. leave all the checkboxes unchecked\n",
    "#     2. Save it in your env.py file under the variable `github_token`\n",
    "# TODO: Add your github username to your env.py file under the variable `github_username`\n",
    "# TODO: Add more repositories to the `REPOS` list below.\n",
    "\n",
    "REPOS = urls_repo['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f280f6",
   "metadata": {},
   "source": [
    "0-250 seem okay \n",
    "250-500  had an error\n",
    "460-470 had an error\n",
    "480-500 was good\n",
    "Repo index number 468 eip-work/kuboard-press no longer exists and is causing problems. # 468 will be dropped from csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763ccb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b5e72cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": f\"token {github_token}\", \"User-Agent\": github_username}\n",
    "\n",
    "if headers[\"Authorization\"] == \"token \" or headers[\"User-Agent\"] == \"\":\n",
    "    raise Exception(\n",
    "        \"You need to follow the instructions marked TODO in this script before trying to use it\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ea4f2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def github_api_request(url: str) -> Union[List, Dict]:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response_data = response.json()\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            f\"Error response from github api! status code: {response.status_code}, \"\n",
    "            f\"response: {json.dumps(response_data)}\"\n",
    "        )\n",
    "    return response_data\n",
    "\n",
    "\n",
    "def get_repo_language(repo: str) -> str:\n",
    "    url = f\"https://api.github.com/repos/{repo}\"\n",
    "    repo_info = github_api_request(url)\n",
    "    if type(repo_info) is dict:\n",
    "        repo_info = cast(Dict, repo_info)\n",
    "        if \"language\" not in repo_info:\n",
    "            raise Exception(\n",
    "                \"'language' key not round in response\\n{}\".format(json.dumps(repo_info))\n",
    "            )\n",
    "        return repo_info[\"language\"]\n",
    "    raise Exception(\n",
    "        f\"Expecting a dictionary response from {url}, instead got {json.dumps(repo_info)}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_repo_contents(repo: str) -> List[Dict[str, str]]:\n",
    "    url = f\"https://api.github.com/repos/{repo}/contents/\"\n",
    "    contents = github_api_request(url)\n",
    "    if type(contents) is list:\n",
    "        contents = cast(List, contents)\n",
    "        return contents\n",
    "    raise Exception(\n",
    "        f\"Expecting a list response from {url}, instead got {json.dumps(contents)}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_readme_download_url(files: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Takes in a response from the github api that lists the files in a repo and\n",
    "    returns the url that can be used to download the repo's README file.\n",
    "    \"\"\"\n",
    "    for file in files:\n",
    "        if file[\"name\"].lower().startswith(\"readme\"):\n",
    "            return file[\"download_url\"]\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def process_repo(repo: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Takes a repo name like \"gocodeup/codeup-setup-script\" and returns a\n",
    "    dictionary with the language of the repo and the readme contents.\n",
    "    \"\"\"\n",
    "    contents = get_repo_contents(repo)\n",
    "    readme_download_url = get_readme_download_url(contents)\n",
    "    if readme_download_url == \"\":\n",
    "        readme_contents = \"\"\n",
    "    else:\n",
    "        readme_contents = requests.get(readme_download_url).text\n",
    "    return {\n",
    "        \"repo\": repo,\n",
    "        \"language\": get_repo_language(repo),\n",
    "        \"readme_contents\": readme_contents,\n",
    "    }\n",
    "\n",
    "\n",
    "def scrape_github_data() -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Loop through all of the repos and process them. Returns the processed data.\n",
    "    \"\"\"\n",
    "    return [process_repo(repo) for repo in REPOS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5022451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        data = scrape_github_data()\n",
    "        json.dump(data, open(\"data.json\", \"w\"), indent=1)\n",
    "    except: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b7c2cfbe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scrape repos for information.\n",
    "df = scrape_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4ec36e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7497124f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>[![freeCodeCamp Social Banner](https://s3.amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>getify/You-Dont-Know-JS</td>\n",
       "      <td>None</td>\n",
       "      <td># You Don't Know JS Yet (book series) - 2nd Ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft/vscode</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td># Visual Studio Code - Open Source (\"Code - OS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>electron/electron</td>\n",
       "      <td>C++</td>\n",
       "      <td>[![Electron Logo](https://electronjs.org/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>axios/axios</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>&lt;h1 align=\"center\"&gt;\\n   &lt;b&gt;\\n        &lt;a href=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        repo    language  \\\n",
       "0  freeCodeCamp/freeCodeCamp  TypeScript   \n",
       "1    getify/You-Dont-Know-JS        None   \n",
       "2           microsoft/vscode  TypeScript   \n",
       "3          electron/electron         C++   \n",
       "4                axios/axios  JavaScript   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  [![freeCodeCamp Social Banner](https://s3.amaz...  \n",
       "1  # You Don't Know JS Yet (book series) - 2nd Ed...  \n",
       "2  # Visual Studio Code - Open Source (\"Code - OS...  \n",
       "3  [![Electron Logo](https://electronjs.org/image...  \n",
       "4  <h1 align=\"center\">\\n   <b>\\n        <a href=\"...  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "17aa6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls.to_csv('urls_final1.csv', index=Fal\n",
    "df.to_csv('readme_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53e94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.language.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ebdad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9473df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fa4dc",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc64fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    # we will normalize our data into standard NFKD unicode, feed it into an ascii encoding\n",
    "    # decode it back into UTF-8\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    # utilize our regex substitution to remove our undesirable characters, then lowercase\n",
    "    string = re.sub(r\"[^\\w0-9'\\s]\", '', string).lower()\n",
    "    return string\n",
    "\n",
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # make our tokenizer, taken from nltk's ToktokTokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    # apply our tokenizer's tokenization to the string being input, ensure it returns a string\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "    \n",
    "    return string\n",
    "\n",
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # create our lemmatizer object\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    # use a list comprehension to lemmatize each word\n",
    "    # string.split() => output a list of every token inside of the document\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    # glue the lemmas back together by the strings we split on\n",
    "    string = ' '.join(lemmas)\n",
    "    #return the altered document\n",
    "    return string\n",
    "\n",
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # assign our stopwords from nltk into stopword_list\n",
    "    stopword_list = stopwords.words('english')\n",
    "    # utilizing set casting, i will remove any excluded stopwords\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    # add in any extra words to my stopwords set using a union\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    # split our document by spaces\n",
    "    words = string.split()\n",
    "    # every word in our document, as long as that word is not in our stopwords\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    # glue it back together with spaces, as it was so it shall be\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    # return the document back\n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c68fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply basic clean to content\n",
    "df['clean_text']= df.readme_contents.apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fa876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# atokenize \n",
    "df['clean_text']= df.clean_text.apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a538fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize\n",
    "df['clean_text']= df.clean_text.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "df['clean_text']= df.clean_text.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d31b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eac331",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefa270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, target):\n",
    "    '''\n",
    "    split_date takes in a dataframe  and target variable and splits into train , validate, test \n",
    "    and stratifies on target variable\n",
    "    \n",
    "    The split is 20% test 80% train/validate. Then 30% of 80% validate and 70% of 80% train.\n",
    "    Aproximately (train 56%, validate 24%, test 20%)\n",
    "    \n",
    "    returns train, validate, and test \n",
    "    '''\n",
    "    # split test data from train/validate\n",
    "    train_validate, test = train_test_split(df, test_size=.2, \n",
    "                                        random_state=123, \n",
    "                                        stratify=df[target])\n",
    "\n",
    "    # split train from validate\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, \n",
    "                                   random_state=123, \n",
    "                                   stratify=train_validate[target])\n",
    "\n",
    "                                   \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = split_data(inshort_df,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7fa70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a937dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdf974ea",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e3a9a",
   "metadata": {},
   "source": [
    "### look at how many of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec2cdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
