{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9dfcb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import requests\n",
    "from env import github_token, github_username\n",
    "import unicodedata\n",
    "import nltk\n",
    "import prepare as p\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import model as m\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d365d8",
   "metadata": {},
   "source": [
    "# CodeUp-DS-NLP-Project\n",
    " \n",
    "### Project Goals \n",
    "* The goal of this classification project is to first identify key words of the programming language and create a machine learning model that can effectly predict the programming language used.\n",
    "### The Plan\n",
    "* Aquire ReadMe data from GitHub repositories via webscraping.\n",
    "* Prepare data for exploration by:\n",
    "    * Convert text to all lower case for normalcy.\n",
    "    * Remove any accented characters, non-ASCII characters.\n",
    "    * Remove special characters.\n",
    "    * Lemmatize the words.\n",
    "    * Remove stopwords.\n",
    "    * Store the clean text and the original text for use in future notebooks.\n",
    "#### Explore data in search of key features with the basic following questions:\n",
    "* What are the most common words in READMEs?\n",
    "* Does the length of the README vary by programming language?\n",
    "* Do different programming languages use a different number of unique words?\n",
    "* Are there any words that uniquely identify a programming language?\n",
    "#### Develop a Model to predict happiness score\n",
    "* Use key words identified to build predictive models of different types\n",
    "* Evaluate models on train and validate data samples\n",
    "* Select the best model based on accuracy\n",
    "* Evaluate the best model on test data samples\n",
    "#### Draw conclusions\n",
    "\n",
    "### Steps to Reproduce\n",
    "* Clone this repo.\n",
    "* Acquire the data from GitHub\n",
    "* Put the data in the file containing the cloned repo.\n",
    "* Run notebook\n",
    "### Conclusions\n",
    "* Decision Tree model Accuracy scores:\n",
    "    \n",
    "        * 0.704762 on training data samples\n",
    "        * 0.637363 on validate data samples\n",
    "        * 0.671052 on test data samples\n",
    "        \n",
    "#### Key TakeAway:\n",
    "    Decision Tree model was successful on all train, validate and test data sets. \n",
    "### Recommendations\n",
    "\n",
    "   * Consider aquiring larger \"text\" datasets\n",
    "   * Consider hyperparameter tunning\n",
    "   * Consider gradient boosting algorithims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa834c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#url = \"https://github.com/search?3&q=stars%3A%3E0&s=stars&type=Repositories\"\n",
    "#reqs = requests.get(url)\n",
    "#soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "#urls = []\n",
    "#for link in soup.find_all('a',class_=\"v-align-middle\"):\n",
    "#    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c111c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember the lesson that Rosy showed you\n",
    "#for i in range(1,50):\n",
    "#    print(i)\n",
    "#    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18de792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#url = \"https://github.com/search?3&q=stars%3A%3E0&s=stars&type=Repositories\"\n",
    "#reqs = requests.get(url)\n",
    "#soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "#urls = []\n",
    "#for link in soup.find_all('a',class_=\"v-align-middle\"):\n",
    "#    urls.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls_repo = pd.read_csv('urls.csv', index_col=0)\n",
    "#urls_repo['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPOS = urls_repo['0']\n",
    "\n",
    "headers = {\"Authorization\": f\"token {github_token}\", \"User-Agent\": github_username}\n",
    "\n",
    "if headers[\"Authorization\"] == \"token \" or headers[\"User-Agent\"] == \"\":\n",
    "    raise Exception(\n",
    "        \"You need to follow the instructions marked TODO in this script before trying to use it\"\n",
    "    )\n",
    "\n",
    "\n",
    "def github_api_request(url: str) -> Union[List, Dict]:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response_data = response.json()\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            f\"Error response from github api! status code: {response.status_code}, \"\n",
    "            f\"response: {json.dumps(response_data)}\"\n",
    "        )\n",
    "    return response_data\n",
    "\n",
    "\n",
    "def get_repo_language(repo: str) -> str:\n",
    "    url = f\"https://api.github.com/repos/{repo}\"\n",
    "    repo_info = github_api_request(url)\n",
    "    if type(repo_info) is dict:\n",
    "        repo_info = cast(Dict, repo_info)\n",
    "        if \"language\" not in repo_info:\n",
    "            raise Exception(\n",
    "                \"'language' key not round in response\\n{}\".format(json.dumps(repo_info))\n",
    "            )\n",
    "        return repo_info[\"language\"]\n",
    "    raise Exception(\n",
    "        f\"Expecting a dictionary response from {url}, instead got {json.dumps(repo_info)}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_repo_contents(repo: str) -> List[Dict[str, str]]:\n",
    "    url = f\"https://api.github.com/repos/{repo}/contents/\"\n",
    "    contents = github_api_request(url)\n",
    "    if type(contents) is list:\n",
    "        contents = cast(List, contents)\n",
    "        return contents\n",
    "    raise Exception(\n",
    "        f\"Expecting a list response from {url}, instead got {json.dumps(contents)}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_readme_download_url(files: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Takes in a response from the github api that lists the files in a repo and\n",
    "    returns the url that can be used to download the repo's README file.\n",
    "    \"\"\"\n",
    "    for file in files:\n",
    "        if file[\"name\"].lower().startswith(\"readme\"):\n",
    "            return file[\"download_url\"]\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def process_repo(repo: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Takes a repo name like \"gocodeup/codeup-setup-script\" and returns a\n",
    "    dictionary with the language of the repo and the readme contents.\n",
    "    \"\"\"\n",
    "    contents = get_repo_contents(repo)\n",
    "    readme_download_url = get_readme_download_url(contents)\n",
    "    if readme_download_url == \"\":\n",
    "        readme_contents = \"\"\n",
    "    else:\n",
    "        readme_contents = requests.get(readme_download_url).text\n",
    "    return {\n",
    "        \"repo\": repo,\n",
    "        \"language\": get_repo_language(repo),\n",
    "        \"readme_contents\": readme_contents,\n",
    "    }\n",
    "\n",
    "\n",
    "def scrape_github_data() -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Loop through all of the repos and process them. Returns the processed data.\n",
    "    \"\"\"\n",
    "    return [process_repo(repo) for repo in REPOS]\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    data = scrape_github_data()\n",
    "#    json.dump(data, open(\"data.json\", \"w\"), indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5355a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls_df = scrape_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87317fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df=pd.DataFrame(urls_df)\n",
    "df = pd.read_csv('readme_df.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d31841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.language == 'Java') | (df.language=='JavaScript') | (df.language=='Python') | (df.language=='TypeScript')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0de5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop = True, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ddb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    # we will normalize our data into standard NFKD unicode, feed it into an ascii encoding\n",
    "    # decode it back into UTF-8\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    # utilize our regex substitution to remove our undesirable characters, then lowercase\n",
    "    string = re.sub(r\"[^\\w0-9'\\s]\", '', string).lower()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d745e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inshort_df[‘clean_text’] = inshort_df.content.apply(clean).apply(' ’.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcea906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']= df.readme_contents.apply(p.basic_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765e081",
   "metadata": {},
   "source": [
    "# start here after scrapping\n",
    "### get dataframe from csv and clean using prep functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be324d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire readme data\n",
    "df = pd.read_csv('readme_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa075cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data\n",
    "df = p.data_prep(df)\n",
    "\n",
    "# prepare text for exploration \n",
    "df = p.text_prep(df)\n",
    "\n",
    "\n",
    "# split data: train, validate and test\n",
    "train, validate, test = p.split_data(df, 'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476131f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "656646b2",
   "metadata": {},
   "source": [
    "### RATIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.concat([df.language.value_counts(),\n",
    "                    df.language.value_counts(normalize=True)], axis=1)\n",
    "labels.columns = ['n', 'percent']\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_counts_and_ratios(df, column):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and a string of a single column\n",
    "    Returns a dataframe with absolute value counts and percentage value counts\n",
    "    \"\"\"\n",
    "    labels = pd.concat([df[column].value_counts(),\n",
    "                    df[column].value_counts(normalize=True)], axis=1)\n",
    "    labels.columns = ['n', 'percent']\n",
    "    labels\n",
    "    return labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa82823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # make our tokenizer, taken from nltk's ToktokTokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    # apply our tokenizer's tokenization to the string being input, ensure it returns a string\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea332d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']= df.clean_text.apply(p.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d3e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # create our lemmatizer object\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    # use a list comprehension to lemmatize each word\n",
    "    # string.split() => output a list of every token inside of the document\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    # glue the lemmas back together by the strings we split on\n",
    "    string = ' '.join(lemmas)\n",
    "    #return the altered document\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff61a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']= df.clean_text.apply(p.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc95bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_words = [\"'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c771dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # assign our stopwords from nltk into stopword_list\n",
    "    stopword_list = stopwords.words('english')\n",
    "    # utilizing set casting, i will remove any excluded stopwords\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    # add in any extra words to my stopwords set using a union\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    # split our document by spaces\n",
    "    words = string.split()\n",
    "    # every word in our document, as long as that word is not in our stopwords\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    # glue it back together with spaces, as it was so it shall be\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    # return the document back\n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a304edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']= df.clean_text.apply(p.remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6445e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424f2599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe529d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, target):\n",
    "    \"\"\"\"\n",
    "    split_date takes in a dataframe  and target variable and splits into train , validate, test\n",
    "    and stratifies on target variable\n",
    "    The split is 20% test 80% train/validate. Then 30% of 80% validate and 70% of 80% train.\n",
    "    Aproximately (train 56%, validate 24%, test 20%)\n",
    "    returns train, validate, and test\n",
    "    \"\"\"\n",
    "    # split test data from train/validate\n",
    "    train_validate, test = train_test_split(df, test_size=.2,\n",
    "                                        random_state=123,\n",
    "                                        stratify=df[target])\n",
    "    # split train from validate\n",
    "    train, validate = train_test_split(train_validate, test_size=.3,\n",
    "                                   random_state=123,\n",
    "                                   stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f03115",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = split_data(df, 'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2932c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.language.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ae02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3821715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting basic style parameters for matplotlib\n",
    "plt.rc('figure', figsize=(13, 7))\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10757fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "JavaScript_words = ' '.join(train[train.language == 'JavaScript'].clean_text).split(' ')\n",
    "Java_words = ' '.join(train[train.language == 'Java'].clean_text).split(' ')\n",
    "Python_words = ' '.join(train[train.language == 'Python'].clean_text).split(' ')\n",
    "TypeScript_words = ' '.join(train[train.language == 'TypeScript'].clean_text).split(' ')\n",
    "All_words = ' '.join(train.clean_text).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d4ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cac035",
   "metadata": {},
   "outputs": [],
   "source": [
    "JavaScript_freq = pd.Series(JavaScript_words).value_counts()\n",
    "Java_freq = pd.Series(Java_words).value_counts()\n",
    "Python_freq = pd.Series(Python_words).value_counts()\n",
    "TypeScript_freq = pd.Series(TypeScript_words).value_counts()\n",
    "All_words_freq = pd.Series(All_words).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e604363",
   "metadata": {},
   "outputs": [],
   "source": [
    "JavaScript_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Java_freq.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "Python_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05973a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "TypeScript_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = (pd.concat([JavaScript_freq, Java_freq, Python_freq, TypeScript_freq, All_words_freq], axis=1, sort=True)\n",
    "                .set_axis(['JavaScript', 'Java', 'Python', 'TypeScript', 'AllWords'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bebf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t test of length of documnet number of words verse prog lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642748db",
   "metadata": {},
   "source": [
    "### TOP 10 ALL Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f50a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_words_cloud = word_counts.sort_values(by='AllWords', ascending=False).head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a81a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_cloud= top_words_cloud.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_cloud = \" \".join(top_words_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a17b07",
   "metadata": {},
   "source": [
    "### create word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13581e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "img = WordCloud(background_color='white',colormap='Accent').generate(top_words_cloud)\n",
    "# WordCloud() produces an image object, which can be displayed with plt.imshow\n",
    "plt.imshow(img)\n",
    "# axis aren't very useful for a word cloud\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b6247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cloud = WordCloud(background_color='white', height=1000, width=400).generate(' '.join(all_words))\n",
    "ham_cloud = WordCloud(background_color='white', height=600, width=800).generate(' '.join(ham_words))\n",
    "spam_cloud = WordCloud(background_color='white', height=600, width=800).generate(' '.join(spam_words))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "axs = [plt.axes([0, 0, .5, 1]), plt.axes([.5, .5, .5, .5]), plt.axes([.5, 0, .5, .5])]\n",
    "\n",
    "axs[0].imshow(all_cloud)\n",
    "axs[1].imshow(ham_cloud)\n",
    "axs[2].imshow(spam_cloud)\n",
    "\n",
    "axs[0].set_title('All Words')\n",
    "axs[1].set_title('Ham')\n",
    "axs[2].set_title('Spam')\n",
    "\n",
    "for ax in axs: ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f8f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe550aed",
   "metadata": {},
   "source": [
    "### Top 10 Words unique to Python Vs JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fce0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = pd.concat([word_counts[word_counts.JavaScript == 0].sort_values(by='Python').tail(10),\n",
    "           word_counts[word_counts.Python == 0].sort_values(by='JavaScript').tail(10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the percentage of spam vs ham\n",
    "(word_counts\n",
    " .assign(p_spam=word_counts.spam / word_counts['all'],\n",
    "         p_ham=word_counts.ham / word_counts['all'])\n",
    " .sort_values(by='all')\n",
    " [['p_spam', 'p_ham']]\n",
    " .tail(20)\n",
    " .sort_values('p_ham')\n",
    " .plot.barh(stacked=True))\n",
    "\n",
    "plt.title('Proportion of Spam vs Ham for the 20 most common words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bc0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the percentage of spam vs ham\n",
    "(word_counts\n",
    " .assign(p_python=word_counts.Python / word_counts['AllWords'],\n",
    "         p_javascript=word_counts.JavaScript / word_counts['AllWords'])\n",
    " .sort_values(by='AllWords')\n",
    " [['p_python', 'p_javascript']]\n",
    " .tail(20)\n",
    " .sort_values('p_javascript')\n",
    " .plot.barh(stacked=True))\n",
    "\n",
    "plt.title('Proportion of Python vs JavaScript for the 20 most common words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(word_counts\n",
    " [(word_counts.Python > 10) & (word_counts.JavaScript > 10)]\n",
    " .assign(ratio=lambda df: df.Python / (df.JavaScript + .01))\n",
    " .sort_values(by='ratio')\n",
    " .pipe(lambda df: pd.concat([df.head(), df.tail()])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d079eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_JavaScript_bigrams = (pd.Series(nltk.ngrams(JavaScript_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_JavaScript_bigrams.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_JavaScript_bigrams.sort_values(ascending=False).plot.barh(color='pink', width=.9, figsize=(10, 6))\n",
    "\n",
    "plt.title('20 Most frequently occuring JavaScript bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# Occurances')\n",
    "\n",
    "# make the labels pretty\n",
    "ticks, _ = plt.yticks()\n",
    "labels = top_20_JavaScript_bigrams.reset_index()['index'].apply(lambda t: t[0] + ' ' + t[1])\n",
    "_ = plt.yticks(ticks, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e89c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_Python_bigrams = (pd.Series(nltk.ngrams(Python_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_Python_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_Python_bigrams.sort_values(ascending=False).plot.barh(color='pink', width=.9, figsize=(10, 6))\n",
    "\n",
    "plt.title('20 Most frequently occuring Python bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# Occurances')\n",
    "\n",
    "# make the labels pretty\n",
    "ticks, _ = plt.yticks()\n",
    "labels = top_20_Python_bigrams.reset_index()['index'].apply(lambda t: t[0] + ' ' + t[1])\n",
    "_ = plt.yticks(ticks, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e7afa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_counts['raw_count'] = word_counts.AllWords\n",
    "#.assign(frequency=lambda df: df.raw_count / df.raw_count.sum()).assign(augmented_frequency=lambda df: df.frequency / df.frequency.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f57008",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['frequency'] = word_counts.raw_count / word_counts.raw_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['augmented_frequency'] = word_counts.frequency / word_counts.frequency.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bd384",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a49bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# same basic process as any sklearn transformation:\n",
    "# make the thing\n",
    "cv = CountVectorizer()\n",
    "# use the thing\n",
    "bag_of_words = cv.fit_transform(train.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e7a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bow = pd.DataFrame(bag_of_words.todense())\n",
    "bow.columns = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa8dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "bag_of_words = tfidf.fit_transform(train.clean_text)\n",
    "\n",
    "pd.DataFrame(bag_of_words.todense(), \n",
    "             columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f4bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_features = pd.Series(\n",
    "    dict(\n",
    "        zip(\n",
    "            tfidf.get_feature_names(), tfidf.idf_\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the higher the score does not mean the more frequent it appears.\n",
    "# what it means is that, tha particular word has more weight in determining language\n",
    "bag_of_features.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 3))\n",
    "bag_of_grams = cv.fit_transform(train.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eae054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.clean_text\n",
    "y_train = train.language\n",
    "\n",
    "X_validate = validate.clean_text\n",
    "y_validate = validate.language\n",
    "\n",
    "X_test = test.clean_text\n",
    "y_test = test.language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01bdc4a",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb1e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever transformations we apply to X_train need to be applied to X_test\n",
    "cv = CountVectorizer()\n",
    "X_bow = cv.fit_transform(X_train)\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "tree.fit(X_bow, y_train)\n",
    "tree.score(X_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d5129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever transformations we apply to X_train need to be applied to X_test\n",
    "X_bow_val = cv.transform(X_validate)\n",
    "tree.score(X_bow_val, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcef88e",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8dac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever transformations we apply to X_train need to be applied to X_test\n",
    "cv1 = CountVectorizer()\n",
    "X_bow1 = cv1.fit_transform(X_train)\n",
    "rf = RandomForestClassifier(max_depth =6, \n",
    "                            min_samples_leaf = 2, \n",
    "                            random_state=123)\n",
    "rf.fit(X_bow1, y_train)\n",
    "rf.score(X_bow1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c194bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatever transformations we apply to X_train need to be applied to X_test\n",
    "X_bow_val = cv1.transform(X_validate)\n",
    "rf.score(X_bow_val, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9755f3",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b95e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer()\n",
    "X_bow = cv2.fit_transform(X_train)\n",
    "knn = KNeighborsClassifier(n_neighbors=6, weights='uniform')\n",
    "knn.fit(X_bow, y_train)\n",
    "knn.score(X_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34630496",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow_val = cv2.transform(X_validate)\n",
    "knn.score(X_bow_val, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac08ce9",
   "metadata": {},
   "source": [
    "# Start Here with models...Final Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a3a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_validate,y_validate, X_test, y_test = m.model_prep(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3931c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = m.cv_countvectorizer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77895d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTree_Train,DecisionTree_Validate=m.get_tree(X_train,y_train,X_validate,y_validate, X_test,y_test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "481f5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Train,KNN_Validate = m.get_knn(X_train,y_train,X_validate,y_validate, X_test,y_test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b020407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_Train,RandomForest_Validate =m.get_forest(X_train,y_train,X_validate,y_validate, X_test,y_test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19603219",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eval(KNN_Train, KNN_Validate, RandomForest_Train, RandomForest_Validate, DecisionTree_Train, DecisionTree_Validate, evaluate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5791734",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTree_Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a977b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTree_Train,DecisionTree_Validate=m.get_tree(X_train,y_train,X_validate,y_validate, X_test,y_test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0407b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Train,KNN_Validate = m.get_knn(X_train,y_train,X_validate,y_validate, X_test,y_test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_Train,RandomForest_Validate =m.get_forest(X_train,y_train,X_validate,y_validate, X_test,y_test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52aeda92",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['DecisionTree_Train', 'DecisionTree_Validate', 'RandomForest_Train', 'RandomForest_Validate', 'KNN_Train', 'KNN_Validate']\n",
    "def make_stats_df():\n",
    "    '''\n",
    "    Function creates dataframe for results of pearsonsr statistical \n",
    "    test for all features.\n",
    "    '''\n",
    "    evaluate_df = pd.DataFrame()\n",
    "    evaluate_df['Models'] = models\n",
    "    return evaluate_df\n",
    "\n",
    "def final_eval(a, b, c, d, e, f, df):\n",
    "    \n",
    "\n",
    "\n",
    "    scores = [a, b, c, d, e, f]\n",
    "    df['Scores']=scores\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b577911",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_df = make_stats_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde9138e",
   "metadata": {},
   "source": [
    "### Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "814c27a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree_Train</td>\n",
       "      <td>0.704762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree_Validate</td>\n",
       "      <td>0.637363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest_Train</td>\n",
       "      <td>0.623810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest_Validate</td>\n",
       "      <td>0.494505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_Train</td>\n",
       "      <td>0.580952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN_Validate</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Models    Scores\n",
       "0     DecisionTree_Train  0.704762\n",
       "1  DecisionTree_Validate  0.637363\n",
       "2     RandomForest_Train  0.623810\n",
       "3  RandomForest_Validate  0.494505\n",
       "4              KNN_Train  0.580952\n",
       "5           KNN_Validate  0.461538"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_eval(DecisionTree_Train, DecisionTree_Validate, RandomForest_Train, RandomForest_Validate, KNN_Train, KNN_Validate, evaluate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27115e0d",
   "metadata": {},
   "source": [
    "### Modeling Summary\n",
    "\n",
    "#### Baseline Score is 45% (0.45)\n",
    "* The DecisionTree Model out-performed other models on train and validate data sets \n",
    "    * .704762\n",
    "    * .637363\n",
    "    \n",
    "* The KNN Model came in dead last only slightly out-performing the baseline score\n",
    "    * .580952\n",
    "    * .461538\n",
    "    \n",
    "* The ideal model is expected to have out-performed the baseline score & have the highest accuracy score in comparison to other models.\n",
    "    * For this reason DecisionTree model will now be fit to the test data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f63518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_test(x_train, y_train, x_validate, y_validate, x_test, y_test,cv):\n",
    "    '''\n",
    "    Function gets Decision Tree model accuracy on train and validate data set \n",
    "    ''' \n",
    "    # create decision tree model using defaults and random state to replicate results\n",
    "    tree = DecisionTreeClassifier(max_depth=3,radom_state=123)\n",
    "\n",
    "    # fit model on training data\n",
    "    X_bow = cv.fit_transform(x_train)\n",
    "    tree.fit(X_bow, y_train)\n",
    "    train_score= tree.score(X_bow, y_train)\n",
    "    \n",
    "    # fit model on validate data\n",
    "    X_bow_val = cv.transform(x_validate)\n",
    "    val_score =tree.score(X_bow_val, y_validate)\n",
    "\n",
    "    # fit model on test data\n",
    "    X_bow_test = cv.transform(x_test)\n",
    "    \n",
    "    test_score =tree.score(X_bow_test, y_test)\n",
    "\n",
    "    #return train_score, val_score, test_score\n",
    "    print('Accuracy of Decision Tree classifier model on test set: {:.2f}'\n",
    "      .format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf8b059",
   "metadata": {},
   "source": [
    "### Decision Tree Model on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "296ac7aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_tree_test(\u001b[43mX_train\u001b[49m, y_train, X_validate, y_validate, X_test, y_test,cv)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "get_tree_test(X_train, y_train, X_validate, y_validate, X_test, y_test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e8008d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6710526315789473"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb910b81",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "* Decision Tree model Accuracy scores:\n",
    "    \n",
    "        * 0.704762 on training data samples\n",
    "        * 0.637363 on validate data samples\n",
    "        * 0.671052 on test data samples\n",
    "        \n",
    "#### Key TakeAway:\n",
    "    Decision Tree model was successful on all train, validate and test data sets. \n",
    "\n",
    "### Recommendations\n",
    "\n",
    "   * Consider aquiring larger \"text\" datasets\n",
    "   * Consider hyperparameter tunning\n",
    "   * Consider gradient boosting algorithims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d239d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
